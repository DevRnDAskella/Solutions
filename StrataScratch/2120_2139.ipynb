{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2120\n",
    "\n",
    "```The marketing team is evaluating the performance of their previously ran promotions.They are especially interested in comparing the sales on the first day vs. the last day of each promotion. Segment the results by promotion and find the percentage of transactions that happened on the first and last day of each. Your output should contain the promotion ID, percentage of transactions on the first day, and percentage of transactions on the last day.```"
   ],
   "id": "f20e8461beb57150"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT oo.promotion_id,\n",
    "       100.0 * AVG(CASE WHEN date = start_date THEN 1 ELSE 0 END) AS pct_first_day,\n",
    "       100.0 * AVG(CASE WHEN date = end_date THEN 1 ELSE 0 END)   AS pct_first_day\n",
    "FROM online_sales_promotions AS osp\n",
    "         JOIN online_orders AS oo ON osp.promotion_id = oo.promotion_id\n",
    "GROUP BY oo.promotion_id"
   ],
   "id": "38af7052e9bb24bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(online_sales_promotions, online_orders, how='inner', on='promotion_id')\n",
    "\n",
    "# df['is_start'] = df.apply(lambda row: 1 if row['start_date'] == row['date'] else 0, axis=1)\n",
    "# df['is_end'] = df.apply(lambda row: 1 if row['end_date'] == row['date'] else 0, axis=1)\n",
    "\n",
    "df['is_start'] = (df['start_date'] == df['date']).astype('int')\n",
    "df['is_end'] = (df['end_date'] == df['date']).astype('int')\n",
    "\n",
    "result = df.groupby('promotion_id', as_index=False).agg(\n",
    "    is_start_date=pd.NamedAgg(column='is_start', aggfunc=lambda series: series.mean() * 100),\n",
    "    is_end_date=pd.NamedAgg(column='is_end', aggfunc=lambda series: series.mean() * 100)\n",
    ")"
   ],
   "id": "b1a8e813249fc5d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2121\n",
    "\n",
    "```The marketing department is assessing the success of their promotional campaigns. You have been asked to find which products sold the most units for each promotion. Your output should contain the promotion ID, product ID, and corresponding total sales for the most successful product ID. In the case of a tie, output all results.```"
   ],
   "id": "2698fbc695ba581a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT promotion_id,\n",
    "                    product_id,\n",
    "                    SUM(units_sold)                                                AS total_sales,\n",
    "                    RANK()\n",
    "                    OVER (PARTITION BY promotion_id ORDER BY SUM(units_sold) DESC) AS rnk\n",
    "             FROM online_orders\n",
    "             GROUP BY promotion_id, product_id)\n",
    "SELECT promotion_id, product_id, total_sales\n",
    "FROM cte\n",
    "WHERE rnk = 1"
   ],
   "id": "42149c92ef481d37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = online_orders\n",
    "\n",
    "grouped_df = df.groupby(['promotion_id', 'product_id'], as_index=False).agg(total_units=('units_sold', 'sum'))\n",
    "\n",
    "grouped_df['rnk'] = grouped_df.groupby('promotion_id')['total_units'].rank(method='dense', ascending=False)\n",
    "\n",
    "grouped_df.query('rnk == 1').drop(columns='rnk')"
   ],
   "id": "2d120fb74dad1839"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2122\n",
    "\n",
    "```The VP of Sales feels that some product categories don't sell and can be completely removed from the inventory. As a first pass analysis, they want you to find what percentage of product categories have never been sold.```"
   ],
   "id": "4480546fc43311a1"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT (1 - AVG(sold)) * 100 AS percentage_of_unsold_categories\n",
    "FROM (SELECT op.product_category,\n",
    "             CASE WHEN SUM(oo.units_sold) IS NOT NULL THEN 1 ELSE 0 END AS sold\n",
    "      FROM online_product_categories opc\n",
    "               LEFT JOIN online_products op ON op.product_category = opc.category_id\n",
    "               LEFT JOIN online_orders oo USING (product_id)\n",
    "      GROUP BY op.product_category) t1"
   ],
   "id": "4bd38add3a91957b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2124\n",
    "\n",
    "```You have been tasked with finding the top two single-channel media types (ranked in decreasing order) that correspond to the most money the grocery chain had spent on its promotional campaigns. Your output should contain the media type and the total amount spent on the advertising campaign. In the event of a tie, output all results and do not skip ranks.```"
   ],
   "id": "62513dcca18657ee"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH total_cost_by_media_type AS (SELECT media_type,\n",
    "                                         SUM(cost)                                   AS total_cost,\n",
    "                                         DENSE_RANK() OVER (ORDER BY SUM(cost) DESC) AS rnk\n",
    "                                  FROM online_sales_promotions\n",
    "                                  GROUP BY media_type)\n",
    "SELECT media_type, total_cost\n",
    "FROM total_cost_by_media_type\n",
    "WHERE rnk <= 2"
   ],
   "id": "e933ad48bc39d0ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = online_sales_promotions\n",
    "\n",
    "grouped_df = df.groupby('media_type', as_index=False).agg(total_cost=('cost', 'sum'))\n",
    "\n",
    "grouped_df['rnk'] = grouped_df['total_cost'].rank(method='dense', ascending=False)\n",
    "\n",
    "grouped_df.query('rnk <= 2').drop(columns='rnk')"
   ],
   "id": "8669e87043909f5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2125\n",
    "\n",
    "```Calculate and display the minimum, average and the maximum number of days it takes to process a refund for accounts opened from January 1, 2019. Group by billing cycle in months. Note: The time frame for a refund to be fully processed is from settled_at until refunded_at.```"
   ],
   "id": "7096d6cde1d1c90a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql11"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT billing_cycle_in_months,\n",
    "       MIN(refunded_at - settled_at) AS min_days,\n",
    "       AVG(refunded_at - settled_at) AS avg_days,\n",
    "       MAX(refunded_at - settled_at) AS max_days\n",
    "FROM noom_transactions AS nt\n",
    "         JOIN noom_signups AS ns ON nt.signup_id = ns.signup_id\n",
    "         LEFT JOIN noom_plans AS np ON ns.plan_id = np.plan_id\n",
    "WHERE DATE_TRUNC('year', started_at) >= '2019-01-01'\n",
    "GROUP BY billing_cycle_in_months"
   ],
   "id": "8c85007cd95830fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(noom_transactions, noom_signups, how='inner', on='signup_id').merge(noom_plans, how='left', on='plan_id')\n",
    "\n",
    "df['date_diff'] = (df['refunded_at'] - df['settled_at']).dt.days\n",
    "\n",
    "df.query('started_at.dt.year >= 2019').groupby('billing_cycle_in_months', as_index=False).agg(\n",
    "    min_days=('date_diff', 'min'), avg_days=('date_diff', 'mean'), max_days=('date_diff', 'max'))"
   ],
   "id": "bb91dc29fc321665"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2127\n",
    "\n",
    "```Calculate the sales revenue for the year 2021.```"
   ],
   "id": "cddbc42dacbbcf8a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT SUM(order_total) AS revenue\n",
    "FROM amazon_sales\n",
    "WHERE DATE_TRUNC('year', order_date) = '2021-01-01'"
   ],
   "id": "80296c865005437c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = amazon_sales\n",
    "\n",
    "df['year'] = df['order_date'].dt.year\n",
    "\n",
    "df.query('year == 2021')['order_total'].sum()"
   ],
   "id": "d236e207d34f8217"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2128\n",
    "\n",
    "```Calculate the total revenue made per book. Output the book ID and total sales per book. In case there is a book that has never been sold, include it in your output with a value of 0.```"
   ],
   "id": "6fe467137cb4f338"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT ab.book_id, COALESCE(SUM(quantity * unit_price), 0) AS total_sales\n",
    "FROM amazon_books AS ab\n",
    "         LEFT JOIN amazon_books_order_details AS abod ON ab.book_id = abod.book_id\n",
    "GROUP BY ab.book_id"
   ],
   "id": "481f285d8bd2ff7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(amazon_books, amazon_books_order_details, how='left', on='book_id')\n",
    "df['sales'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "df.groupby('book_id', as_index=False).agg(total_sales=('sales', 'sum'))"
   ],
   "id": "9070caf0840d0eea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2129\n",
    "\n",
    "```You are given a list of posts of a Facebook user. Find the average number of likes.```"
   ],
   "id": "7f15c927b83f6988"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT AVG(no_of_likes) AS avg_likes\n",
    "FROM fb_posts"
   ],
   "id": "375a495d964c7ee3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = fb_posts\n",
    "\n",
    "df['no_of_likes'].mean()"
   ],
   "id": "5ff337282ae96f51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2130\n",
    "\n",
    "```Display a list of users who took the same training lessons more than once on the same day. Output their usernames, training IDs, dates and the number of times they took the same lesson.```"
   ],
   "id": "aff0b612e7920929"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql8"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT u_id, training_date, training_id, COUNT(training_id) AS n_attended\n",
    "             FROM training_details\n",
    "             GROUP BY u_id, training_date, training_id\n",
    "             HAVING COUNT(training_id) >= 2)\n",
    "SELECT u_name, training_id, training_date, n_attended\n",
    "FROM cte\n",
    "         JOIN users_training AS ut USING (u_id)"
   ],
   "id": "be5d48c15637a1de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = training_details\n",
    "\n",
    "df.groupby(['u_id', 'training_date', 'training_id'], as_index=False).agg(n_attended=('training_id', 'count')).query(\n",
    "    'n_attended >= 2').merge(users_training, how='inner', on='u_id').drop(columns='u_id')"
   ],
   "id": "a42113eb47c72fc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2132\n",
    "\n",
    "```Given a phone log table that has information about callers' call history, find out the callers whose first and last calls were to the same person on a given day. Output the caller ID, recipient ID, and the date called.```"
   ],
   "id": "e091f4c439952de5"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql12"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT *,\n",
    "                    FIRST_VALUE(recipient_id)\n",
    "                    OVER (PARTITION BY caller_id, DATE_TRUNC('day', date_called)\n",
    "                        ORDER BY date_called)                                     AS first_call,\n",
    "                    FIRST_VALUE(recipient_id)\n",
    "                    OVER (PARTITION BY caller_id, DATE_TRUNC('day', date_called)\n",
    "                        ORDER BY date_called DESC)                                AS last_call,\n",
    "                    COUNT(recipient_id)\n",
    "                    OVER (PARTITION BY caller_id, DATE_TRUNC('day', date_called)) AS n_calls\n",
    "             FROM caller_history)\n",
    "SELECT DISTINCT caller_id, recipient_id AS recipient, date_called::DATE\n",
    "FROM cte\n",
    "WHERE first_call = last_call\n",
    "  AND n_calls > 1"
   ],
   "id": "9acb1d2e1acbed04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['date'] = df['date_called'].dt.date\n",
    "\n",
    "df_1 = df.groupby(['caller_id', 'date'], as_index=False)['recipient_id'].first()\n",
    "\n",
    "df_2 = df.groupby(['caller_id', 'date'], as_index=False)['recipient_id'].last()\n",
    "\n",
    "pd.merge(df_1, df_2, how='inner', on=['caller_id', 'date', 'recipient_id'])"
   ],
   "id": "ab52ec44fdb694c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2137\n",
    "\n",
    "```It's the end-of-year review, and you've been tasked with identifying the city with the most profitable month in 2021. The output should provide the city, the most profitable month, and the profit.```"
   ],
   "id": "c1d3e3fd23cef05a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql9"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT city,\n",
    "                    EXTRACT(MONTH FROM order_date) AS p_month,\n",
    "                    SUM(order_fare)                AS profit,\n",
    "                    MAX(SUM(order_fare)) OVER ()   AS max_profit\n",
    "             FROM lyft_orders AS lo\n",
    "                      JOIN lyft_payment_details AS lpd ON lo.order_id = lpd.order_id\n",
    "             WHERE DATE_TRUNC('year', order_date) = '2021-01-01'\n",
    "             GROUP BY city, p_month)\n",
    "SELECT city, p_month, profit\n",
    "FROM cte\n",
    "WHERE profit = max_profit"
   ],
   "id": "7516b6b45b826bbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(lyft_orders, lyft_payment_details, how='inner', on='order_id')\n",
    "\n",
    "df['year'] = df['order_date'].dt.year\n",
    "\n",
    "df['month'] = df['order_date'].dt.month\n",
    "\n",
    "df.query('year == 2021').groupby(['city', 'month'], as_index=False).agg(profit=('order_fare', 'sum')).nlargest(1,\n",
    "                                                                                                               'profit',\n",
    "                                                                                                               keep='all')"
   ],
   "id": "b3ee618376238bd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2139\n",
    "\n",
    "```You have been asked to calculate the average age by gender of people who filed more than 1 claim in 2021. The output should include the gender and average age rounded to the nearest whole number.```"
   ],
   "id": "9020caebc8e9e5dc"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql10"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT account_id, COUNT(claim_id) AS n_claim\n",
    "             FROM cvs_claims\n",
    "             WHERE DATE_TRUNC('year', date_submitted) = '2021-01-01'\n",
    "             GROUP BY account_id\n",
    "             HAVING COUNT(claim_id) >= 2)\n",
    "SELECT gender, AVG(age) AS avg_age\n",
    "FROM cte\n",
    "         JOIN cvs_accounts AS ca ON cte.account_id = ca.account_id\n",
    "GROUP BY gender"
   ],
   "id": "a16b4bc72a9c7365"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = cvs_claims\n",
    "\n",
    "df['year'] = df['date_submitted'].dt.year\n",
    "\n",
    "df.query('year == 2021').groupby('account_id', as_index=False).agg(n_claims=('claim_id', 'count')).query(\n",
    "    'n_claims >= 2').merge(cvs_accounts, how='inner', on='account_id').groupby('gender', as_index=False).agg(\n",
    "    avg_age=('age', 'mean'))"
   ],
   "id": "7b48f30831695649"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
