{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2020\n",
    "\n",
    "```Which company had the biggest month call decline from March to April 2020? Return the company_id and calls difference for the company with the highest decline.```"
   ],
   "id": "52396e5cd7ddeb7a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH total_call_in_march AS (SELECT company_id,\n",
    "                                    SUM(CASE WHEN call_id IS NOT NULL THEN 1 ELSE 0 END) AS total_calls\n",
    "                             FROM rc_calls\n",
    "                                       JOIN rc_users USING (user_id)\n",
    "                             WHERE date BETWEEN '2020-03-01 00:00:00' AND '2020-03-31 23:59:59'\n",
    "                             GROUP BY company_id),\n",
    "     total_call_in_april AS (SELECT company_id,\n",
    "                                    SUM(CASE WHEN call_id IS NOT NULL THEN 1 ELSE 0 END) AS total_calls\n",
    "                             FROM rc_calls\n",
    "                                      JOIN rc_users USING (user_id)\n",
    "                             WHERE date BETWEEN '2020-04-01 00:00:00' AND '2020-04-30 23:59:59'\n",
    "                             GROUP BY company_id),\n",
    "     variance_calculation AS (SELECT m.company_id,\n",
    "                                     m.total_calls         AS march_total_calls,\n",
    "                                     a.total_calls                 AS april_total_calls,\n",
    "                                     a.total_calls - m.total_calls AS variance\n",
    "                              FROM total_call_in_march AS m\n",
    "                                       JOIN total_call_in_april AS a\n",
    "                                            ON m.company_id = a.company_id)\n",
    "SELECT company_id, march_total_calls, april_total_calls, variance\n",
    "FROM variance_calculation\n",
    "WHERE variance = (SELECT MIN(variance)\n",
    "                  FROM variance_calculation)\n",
    "ORDER BY variance;"
   ],
   "id": "21229b027350835f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "total_call_in_march = pd.merge(rc_calls, rc_users, on='user_id', how='inner').query(\n",
    "    'date >= \"2020-03-01 00:00:00\" & date <= \"2020-03-31 23:59:59\"').groupby('company_id', as_index=False).agg(\n",
    "    total_calls=('call_id', 'count'))\n",
    "\n",
    "total_call_in_april = pd.merge(rc_calls, rc_users, on='user_id', how='inner').query(\n",
    "    'date >= \"2020-04-01 00:00:00\" & date <= \"2020-04-30 23:59:59\"').groupby('company_id', as_index=False).agg(\n",
    "    total_calls=('call_id', 'count'))\n",
    "variance_calculation = pd.merge(total_call_in_march, total_call_in_april, on='company_id', suffixes=('_m', '_a'))\n",
    "variance_calculation['variance'] = variance_calculation['total_calls_a'] - variance_calculation['total_calls_m']\n",
    "variance_calculation.nsmallest(1, 'variance')[['company_id', 'variance']]"
   ],
   "id": "712f4e32f0ddebe7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2021\n",
    "\n",
    "```Redfin helps clients to find agents. Each client will have a unique request_id and each request_id has several calls. For each request_id, the first call is an “initial call” and all the following calls are “update calls”.  What's the average call duration for all initial calls?```"
   ],
   "id": "e046d6d96b8c8769"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT request_id,\n",
    "                    call_duration,\n",
    "                    RANK() OVER (PARTITION BY request_id ORDER BY created_on) AS rnk\n",
    "             FROM redfin_call_tracking)\n",
    "SELECT AVG(call_duration)\n",
    "FROM cte\n",
    "WHERE rnk = 1"
   ],
   "id": "caddac188ffe4d9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = redfin_call_tracking\n",
    "df['rnk'] = df.groupby('request_id')['created_on'].rank(method='first', ascending=True)\n",
    "df.query('rnk == 1')['call_duration'].mean()"
   ],
   "id": "ab7c28cbd6b19a57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2022\n",
    "\n",
    "```Redfin helps clients to find agents. Each client will have a unique request_id and each request_id has several calls. For each request_id, the first call is an “initial call” and all the following calls are “update calls”.  What's the average call duration for all update calls?```"
   ],
   "id": "f4c7eb4eb0af9bc5"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT AVG(call_duration)\n",
    "FROM (SELECT call_duration,\n",
    "             DENSE_RANK() OVER (PARTITION BY request_id ORDER BY created_on) AS rnk\n",
    "      FROM redfin_call_tracking) t1\n",
    "WHERE rnk > 1"
   ],
   "id": "456ab3a3a4d918ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = redfin_call_tracking\n",
    "df['rnk'] = df.sort_values('created_on').groupby('request_id')['created_on'].rank(method='dense')\n",
    "df.query('rnk > 1')['call_duration'].mean()"
   ],
   "id": "e3179bcd454e9ff0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2023\n",
    "\n",
    "```Redfin helps clients to find agents. Each client will have a unique request_id and each request_id has several calls. For each request_id, the first call is an “initial call” and all the following calls are “update calls”.  How many customers have called 3 or more times between 3 PM and 6 PM (initial and update calls combined)?```"
   ],
   "id": "f5d31959691ce546"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH total_calls AS (SELECT request_id, COUNT(call_duration) AS cnt\n",
    "             FROM redfin_call_tracking\n",
    "             WHERE EXTRACT(HOUR FROM created_on) BETWEEN 15 AND 18\n",
    "             GROUP BY request_id\n",
    "             HAVING COUNT(call_duration) >= 3)\n",
    "SELECT COUNT(request_id)\n",
    "FROM total_calls"
   ],
   "id": "5b743141618738c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = redfin_call_tracking\n",
    "df[(df['created_on'].dt.hour >= 15) & (df['created_on'].dt.hour <= 18)].groupby('request_id', as_index=False).agg(\n",
    "    total_cnt=('call_duration', 'count')).query('total_cnt >= 3')['request_id'].count()"
   ],
   "id": "c7552b6160af938f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2025\n",
    "\n",
    "```Write a query that returns a number of users who are exclusive to only one client. Output the client_id and number of exclusive users.```"
   ],
   "id": "2a3fae490f63f1e9"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH distinct_users AS (SELECT user_id, COUNT(DISTINCT client_id)\n",
    "                        FROM fact_events\n",
    "                        GROUP BY user_id\n",
    "                        HAVING COUNT(DISTINCT client_id) = 1)\n",
    "\n",
    "SELECT client_id, COUNT(DISTINCT fe.user_id)\n",
    "FROM fact_events fe\n",
    "         JOIN distinct_users du ON fe.user_id = du.user_id\n",
    "GROUP BY client_id"
   ],
   "id": "27a40b3bf7db5fc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = fact_events\n",
    "grouped_users = df.groupby('user_id', as_index=False).agg(cnt=('client_id', 'nunique')).query('cnt == 1')[\n",
    "    'user_id'].to_list()\n",
    "df.query('user_id.isin(@grouped_users)').groupby('client_id', as_index=False).agg(cnt_users=('user_id', 'nunique'))"
   ],
   "id": "4e89094c194c1686"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2026\n",
    "\n",
    "```Write a query that returns a list of the bottom 2 companies by mobile usage. Company is defined in the customer_id column. Mobile usage is defined as the number of events registered on a client_id == 'mobile'. Order the result by the number of events ascending. In the case where there are multiple companies tied for the bottom ranks (rank 1 or 2), return all the companies. Output the customer_id and number of events.```"
   ],
   "id": "331756b53b2a8b29"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH ranked_mobile_events AS (SELECT customer_id,\n",
    "                    COUNT(1)                              AS events,\n",
    "                    DENSE_RANK() OVER (ORDER BY COUNT(1)) AS rnk\n",
    "             FROM fact_events\n",
    "             WHERE client_id = 'mobile'\n",
    "             GROUP BY customer_id)\n",
    "SELECT customer_id, events\n",
    "FROM ranked_mobile_events\n",
    "WHERE rnk = 1"
   ],
   "id": "fca711fb89e8b383"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = fact_events\n",
    "df.query('client_id == \"mobile\"').groupby('customer_id', as_index=False).agg(events=('client_id', 'count')).nsmallest(2,\n",
    "                                                                                                                      'events',\n",
    "                                                                                                                      keep='all')"
   ],
   "id": "f1c221e14fcf91db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2027\n",
    "\n",
    "```Write a query that returns the company (customer id column) with highest number of users that use desktop only.```"
   ],
   "id": "44902721fe5e7e97"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT customer_id\n",
    "FROM (SELECT customer_id,\n",
    "             RANK() OVER (\n",
    "                 ORDER BY COUNT(DISTINCT user_id) DESC) AS rnk\n",
    "      FROM fact_events\n",
    "      WHERE user_id IN (SELECT user_id\n",
    "                        FROM fact_events\n",
    "                        GROUP BY user_id\n",
    "                        HAVING COUNT(DISTINCT client_id) = 1)\n",
    "        AND client_id = 'desktop'\n",
    "      GROUP BY customer_id) t1\n",
    "WHERE rnk = 1"
   ],
   "id": "699cfcd565d0c31d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = fact_events\n",
    "result = df.groupby('user_id', as_index=False).agg(cnt=('client_id', 'nunique')).query('cnt == 1')\n",
    "result['rnk'] = result.sort_values('cnt', ascending=False)['cnt'].rank(method='dense')\n",
    "df[df['user_id'].isin(result.query('rnk == 1')['user_id'])]['customer_id'].unique()"
   ],
   "id": "14c57ac779a72564"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2028 \n",
    "\n",
    "```Calculate the share of new and existing users for each month in the table. Output the month, share of new users, and share of existing users as a ratio. New users are defined as users who started using services in the current month (there is no usage history in previous months). Existing users are users who used services in current month, but they also used services in any previous month. Assume that the dates are all from the year 2020. HINT: Users are contained in user_id column```"
   ],
   "id": "73824174e691fc8f"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql10"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH started_month AS (SELECT time_id,\n",
    "                    user_id,\n",
    "                    EXTRACT(MONTH FROM time_id)                                      AS current_month,\n",
    "                    EXTRACT(MONTH FROM MIN(time_id)\n",
    "                                       OVER (PARTITION BY user_id ORDER BY time_id)) AS start_month\n",
    "             FROM fact_events)\n",
    "SELECT EXTRACT(MONTH FROM time_id) AS month,\n",
    "       COUNT(DISTINCT user_id) FILTER (WHERE current_month = start_month) * 1.0 /\n",
    "       COUNT(DISTINCT user_id)     AS first_users_cnt,\n",
    "       COUNT(DISTINCT user_id) FILTER (WHERE current_month != start_month) * 1.0 /\n",
    "       COUNT(DISTINCT user_id)     AS\n",
    "                                      existing_users_cnt\n",
    "FROM started_month\n",
    "GROUP BY month\n",
    "ORDER BY month;"
   ],
   "id": "c2644d5b81349b28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = fact_events\n",
    "df['current_month'] = df['time_id'].dt.month\n",
    "df['start_month'] = df.groupby('user_id')['time_id'].transform('min').dt.month\n",
    "df = df[['user_id', 'current_month', 'start_month']].drop_duplicates()\n",
    "df['is_new_user'] = df.apply(lambda x: 1 if x['current_month'] == x['start_month'] else 0, axis = 1)\n",
    "df['is_old_user'] = df.apply(lambda x: 1 if x['current_month'] != x['start_month'] else 0, axis = 1)\n",
    "\n",
    "df.groupby('current_month', as_index=False).agg(share_of_new_users=('is_new_user', 'mean'), share_of_old_users=('is_old_user', 'mean'))"
   ],
   "id": "9e6521e212e46ed3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2031\n",
    "\n",
    "```Get list of signups which have a transaction start date earlier than 10 months ago from March 2021. For all of those users get the average transaction value and group it by the billing cycle. Your output should include the billing cycle, signup_id of the user, and average transaction amount. Sort your results by billing cycle in reverse alphabetical order and signup_id in ascending order.```"
   ],
   "id": "e355832f6d6420b9"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql8"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT p.billing_cycle, t.signup_id, AVG(amt) AS avg_amt\n",
    "FROM transactions t\n",
    "         JOIN signups s ON t.signup_id = s.signup_id\n",
    "         JOIN plans p ON p.id = s.plan_id\n",
    "WHERE t.transaction_start_date < '2021-03-01'::TIMESTAMP - INTERVAL '10 month'\n",
    "GROUP BY p.billing_cycle, t.signup_id\n",
    "ORDER BY p.billing_cycle DESC, t.signup_id ASC"
   ],
   "id": "ba7505b1008965b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(pd.merge(transactions, signups, how='inner', on='signup_id'), plans, how='inner', left_on='plan_id',\n",
    "              right_on='id')\n",
    "df[(df['transaction_start_date'].dt.date < pd.to_datetime('2021-03-01') - relativedelta(months=10))].groupby(\n",
    "    ['billing_cycle', 'signup_id'], as_index=False).agg(amt=('amt', 'mean')).sort_values(['amt', 'signup_id'],\n",
    "                                                                                         ascending=[False, True])"
   ],
   "id": "42e34daf0c8fbf30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2032\n",
    "\n",
    "```Write a query that returns a table containing the number of signups for each weekday and for each billing cycle frequency. The day of the week standard we expect is from Sunday as 0 to Saturday as 6. Output the weekday number (e.g., 1, 2, 3) as rows in your table and the billing cycle frequency (e.g., annual, monthly, quarterly) as columns. If there are NULLs in the output replace them with zeroes.```"
   ],
   "id": "f1e4d1c353a403ee"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql9"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT EXTRACT(DOW FROM signup_start_date)                 AS weekday,\n",
    "       COUNT(*) FILTER (WHERE billing_cycle = 'annual')    AS annual,\n",
    "       COUNT(*) FILTER (WHERE billing_cycle = 'monthly')   AS monthly,\n",
    "       COUNT(*) FILTER (WHERE billing_cycle = 'quarterly') AS quarterly\n",
    "FROM signups s\n",
    "         JOIN plans p ON p.id = s.plan_id\n",
    "GROUP BY weekday\n",
    "ORDER BY weekday"
   ],
   "id": "bf64a72d74fb922c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(signups, plans, how='inner', left_on='plan_id', right_on='id')\n",
    "df['weekday'] = df['signup_start_date'].dt.weekday\n",
    "df.pivot_table(index='weekday', columns='billing_cycle', values='signup_id', aggfunc='nunique').reset_index().fillna(0)"
   ],
   "id": "6f6fe4dfd302fae3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2033\n",
    "\n",
    "```Find the most profitable location. Write a query that calculates the average signup duration and average transaction amount for each location, and then compare these two measures together by taking the ratio of the average transaction amount and average duration for each location. Your output should include the location, average duration, average transaction amount, and ratio. Sort your results from highest ratio to lowest.```"
   ],
   "id": "3d3c88b7be80ae59"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql13"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT location,\n",
    "       AVG(DISTINCT (signup_stop_date - signup_start_date))                  AS mean_duration,\n",
    "       AVG(amt)                                                              AS mean_revenue,\n",
    "       AVG(amt) * 1.0 / AVG(DISTINCT (signup_stop_date - signup_start_date)) AS ratiom\n",
    "FROM transactions t\n",
    "         JOIN signups s ON t.signup_id = s.signup_id\n",
    "GROUP BY location\n",
    "ORDER BY AVG(amt) * 1.0 / AVG(DISTINCT (signup_stop_date - signup_start_date)) DESC"
   ],
   "id": "ba62c02864e5ece6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(transactions, signups, how='inner', on='signup_id')\n",
    "df['diff_signup_date'] = (df['signup_stop_date'] - df['signup_start_date']).dt.days\n",
    "duration_df = df[['location', 'diff_signup_date']].drop_duplicates().groupby('location', as_index=False).agg(mean_duration=('diff_signup_date', 'mean'))\n",
    "revenue_df = df.groupby('location', as_index=False).agg(mean_revenue=('amt', 'mean'))\n",
    "result = pd.merge(duration_df, revenue_df, how='inner', on='location')\n",
    "result['ratio'] = result['mean_revenue'] / result['mean_duration']\n",
    "result.sort_values('ratio', ascending=False)"
   ],
   "id": "bdf2c7fc708770ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2034\n",
    "\n",
    "```You have been asked to calculate the average earnings per order segmented by a combination of weekday (all 7 days) and hour using the column customer_placed_order_datetime. You have also been told that the column order_total represents the gross order total for each order. Therefore, you'll need to calculate the net order total. The gross order total is the total of the order before adding the tip and deducting the discount and refund. Note: In your output, the day of the week should be represented in text format (i.e., Monday). Also, round earnings to 2 decimals```"
   ],
   "id": "8920be71bdc91154"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql11"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT TO_CHAR(customer_placed_order_datetime, 'FMDay') AS weekday, \n",
    "       EXTRACT(HOUR FROM customer_placed_order_datetime) AS hour, \n",
    "      ROUND(AVG((order_total - discount_amount + tip_amount - refunded_amount)::numeric), 2) AS avg_earnings\n",
    "FROM doordash_delivery\n",
    "GROUP BY TO_CHAR(customer_placed_order_datetime, 'FMDay'), EXTRACT(HOUR FROM customer_placed_order_datetime);"
   ],
   "id": "a1dfba53463980fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = doordash_delivery\n",
    "df['order_value'] = df['order_total'] - df['discount_amount'] - df['refunded_amount'] + df['tip_amount']\n",
    "df['hour'] = df['customer_placed_order_datetime'].dt.hour\n",
    "df['weekday'] = df['customer_placed_order_datetime'].dt.strftime('%A').str.strip()\n",
    "result_df =df.groupby(['weekday', 'hour'], as_index=False).agg(avg_earnings=('order_value', 'mean'))\n",
    "result_df['avg_earnings'] = result_df['avg_earnings'].round(2)"
   ],
   "id": "6c4254e5e3aa03a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2035\n",
    "\n",
    "```The company you work for has asked you to look into the average order value per hour during rush hours in the San Jose area. Rush hour is from 15H - 17H inclusive. You have also been told that the column order_total represents the gross order total for each order. Therefore, you'll need to calculate the net order total. The gross order total is the total of the order before adding the tip and deducting the discount and refund. Use the column customer_placed_order_datetime for your calculations.```"
   ],
   "id": "ed263b7673c5a64a"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql12"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT EXTRACT(HOUR FROM customer_placed_order_datetime)                 AS order_hour,\n",
    "       AVG(order_total - discount_amount + tip_amount - refunded_amount) AS avg_earnings\n",
    "FROM delivery_details\n",
    "WHERE delivery_region = 'San Jose'\n",
    "  AND EXTRACT(HOUR FROM customer_placed_order_datetime) BETWEEN 15 AND 17\n",
    "GROUP BY order_hour"
   ],
   "id": "70000c4d3f7287ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = delivery_details\n",
    "df['order_hour'] = df['customer_placed_order_datetime'].dt.hour\n",
    "df['order_value'] = df['order_total'] - df['refunded_amount'] - df['discount_amount'] + df['tip_amount']\n",
    "df.query('delivery_region == \"San Jose\" & order_hour.between(15,17)').groupby('order_hour', as_index=False).agg(final_order_value=('order_value', 'mean'))"
   ],
   "id": "4973762706c84a76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2037\n",
    "\n",
    "```You have been asked to investigate whether there is a correlation between the average total order value and the average time in minutes between placing an order and having it delivered per restaurant. You have also been told that the column order_total represents the gross order total for each order. Therefore, you'll need to calculate the net order total. The gross order total is the total of the order before adding the tip and deducting the discount and refund.```"
   ],
   "id": "ee06261c0cf3dfbd"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql14"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH sq AS (SELECT restaurant_id,\n",
    "                   AVG(order_total + tip_amount - discount_amount -\n",
    "                       refunded_amount) AS avg_gross_order,\n",
    "                   AVG(EXTRACT(EPOCH\n",
    "                               FROM (delivered_to_consumer_datetime -\n",
    "                                     customer_placed_order_datetime)) /\n",
    "                       60)              AS avg_diff_time\n",
    "            FROM delivery_details\n",
    "            GROUP BY restaurant_id)\n",
    "SELECT CORR(avg_diff_time, avg_gross_order)\n",
    "FROM sq"
   ],
   "id": "2306b3d276f08e5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = delivery_details\n",
    "df['gross_order'] = df['order_total'] - df['discount_amount'] - df['refunded_amount'] + df['tip_amount']\n",
    "\n",
    "df['diff_time'] = (df['delivered_to_consumer_datetime'] - df['customer_placed_order_datetime']) / pd.Timedelta(minutes=1)\n",
    "\n",
    "result_df = df.groupby('restaurant_id', as_index=False).agg(avg_gross_order=('gross_order', 'mean'), avg_diff_time=('diff_time', 'mean'))\n",
    "\n",
    "result_df['avg_gross_order'].corr(result_df['avg_diff_time'])"
   ],
   "id": "752fd2a2f612f725"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2039 \n",
    "\n",
    "```Find the number of unique transactions and total sales for each of the product categories in 2017. Output the product categories, number of transactions, and total sales in descending order. The sales column represents the total cost the customer paid for the product so no additional calculations need to be done on the column. Only include product categories that have products sold.```"
   ],
   "id": "c9ff5124c91a1274"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT product_category, COUNT(DISTINCT transaction_id), SUM(sales) AS sales\n",
    "FROM wfm_transactions AS wt\n",
    "         JOIN wfm_products AS wp ON wt.product_id = wp.product_id\n",
    "WHERE EXTRACT(YEAR FROM transaction_date) = 2017\n",
    "GROUP BY product_category\n",
    "ORDER BY sales DESC"
   ],
   "id": "be07194f2a906cf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(wfm_transactions, wfm_products, on='product_id', how='inner')\n",
    "df['year'] = df['transaction_date'].dt.year\n",
    "df.query('year == 2017').groupby('product_category', as_index=False).agg(cnt=('transaction_id', 'nunique'),\n",
    "                                                                         sum=('sales', 'sum'))"
   ],
   "id": "a7a2e84d772c42ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
