{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2140\n",
    "\n",
    "```American Express is reviewing their customers' transactions, and you have been tasked with locating the customer who has the third highest total transaction amount. The output should include the customer's id, as well as their first name and last name. For ranking the customers, use type of ranking with no gaps between subsequent ranks.```"
   ],
   "id": "429406300ddf0eeb"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql6"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT cust_id,\n",
    "                    SUM(total_order_cost)                              AS total_cost,\n",
    "                    DENSE_RANK() OVER (ORDER BY SUM(total_order_cost)) AS rnk\n",
    "             FROM card_orders\n",
    "             GROUP BY cust_id)\n",
    "SELECT cust_id, first_name, last_name\n",
    "FROM cte\n",
    "         JOIN customers AS c ON cte.cust_id = c.id\n",
    "WHERE rnk = 3"
   ],
   "id": "8b0e96eda5a3b0c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = card_orders\n",
    "\n",
    "groped_df = df.groupby('cust_id', as_index=False).agg(total_cost=('total_order_cost', 'sum'))\n",
    "\n",
    "groped_df['rnk'] = groped_df['total_cost'].rank(method='dense')\n",
    "\n",
    "groped_df.query('rnk == 3').merge(customers, how='inner', left_on='cust_id', right_on='id')[\n",
    "    ['id', 'first_name', 'last_name']]"
   ],
   "id": "9567340f177446b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2141\n",
    "\n",
    "```Amazon's information technology department is looking for information on employees' most recent logins. The output should include all information related to each employee's most recent login.```"
   ],
   "id": "1d171831a4f4b39"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql2"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte\n",
    "         AS (SELECT DENSE_RANK()\n",
    "                    OVER (PARTITION BY worker_id ORDER BY login_timestamp DESC),\n",
    "                    id,\n",
    "                    worker_id,\n",
    "                    login_timestamp,\n",
    "                    ip_address,\n",
    "                    country,\n",
    "                    region,\n",
    "                    city,\n",
    "                    device_type\n",
    "             FROM worker_logins)\n",
    "SELECT id,\n",
    "       worker_id,\n",
    "       login_timestamp,\n",
    "       ip_address,\n",
    "       country,\n",
    "       region,\n",
    "       city,\n",
    "       device_type\n",
    "FROM cte\n",
    "WHERE dense_rank = 1\n",
    "ORDER BY id"
   ],
   "id": "b3b958e0453002bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = worker_logins\n",
    "\n",
    "df['rnk'] = df.groupby('worker_id')['login_timestamp'].rank(method='first', ascending=False)\n",
    "\n",
    "df.query('rnk == 1').drop(columns=['rnk'])"
   ],
   "id": "a43990171f40938"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2142\n",
    "\n",
    "```You've been asked by Amazon to find the shipment_id and weight of the third heaviest shipment. Output the shipment_id, and total_weight for that shipment_id. In the event of a tie, do not skip ranks.```"
   ],
   "id": "356029f1d31d7f88"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql3"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT shipment_id,\n",
    "                    SUM(weight) AS total_weight,\n",
    "                    DENSE_RANK() OVER (ORDER BY SUM(weight) DESC)\n",
    "             FROM amazon_shipment\n",
    "             GROUP BY shipment_id)\n",
    "SELECT shipment_id, total_weight\n",
    "FROM cte\n",
    "WHERE dense_rank = 3"
   ],
   "id": "d0a78b83f217ac9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = amazon_shipment\n",
    "\n",
    "grouped_df = df.groupby('shipment_id', as_index=False).agg(total_weight=('weight', 'sum'))\n",
    "\n",
    "grouped_df['rnk'] = grouped_df['total_weight'].rank(method='dense', ascending=False)\n",
    "\n",
    "grouped_df.query('rnk == 3').drop(columns=['rnk'])"
   ],
   "id": "bf4b6358ed6b93af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2143\n",
    "\n",
    "```Bank of Ireland has requested that you detect invalid transactions in December 2022. An invalid transaction is one that occurs outside of the bank's normal business hours. The following are the hours of operation for all branches: Monday - Friday 09:00 - 16:00 Saturday & Sunday Closed Irish Public Holidays 25th and 26th December Determine the transaction ids of all invalid transactions.```"
   ],
   "id": "f56785e72f6bb395"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql7"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT transaction_id\n",
    "FROM boi_transactions\n",
    "WHERE transaction_id IN (SELECT transaction_id\n",
    "                             FROM boi_transactions\n",
    "                             WHERE EXTRACT(MONTH FROM time_stamp) = 12\n",
    "                               AND EXTRACT(DAY FROM time_stamp) IN (25, 26)\n",
    "                             UNION\n",
    "                             SELECT transaction_id\n",
    "                             FROM boi_transactions\n",
    "                             WHERE EXTRACT(DOW FROM time_stamp) IN (6, 0)\n",
    "                             UNION\n",
    "                             SELECT transaction_id\n",
    "                             FROM boi_transactions\n",
    "                             WHERE EXTRACT(DOW FROM time_stamp) BETWEEN 1 AND 5\n",
    "                               AND EXTRACT(HOUR FROM time_stamp) NOT BETWEEN 9 AND 15)"
   ],
   "id": "efcef4d9a8b9104c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = boi_transactions\n",
    "\n",
    "holidays = df.query('time_stamp.dt.month == 12 & time_stamp.dt.day in ([25, 26])')['transaction_id'].to_list()\n",
    "\n",
    "weekends = df.query('time_stamp.dt.dayofweek in ([5, 6])')['transaction_id'].to_list()\n",
    "\n",
    "non_work_hours = df.query('time_stamp.dt.dayofweek.between(0, 4) & ~time_stamp.dt.hour.between(9, 15)')[\n",
    "    'transaction_id'].to_list()\n",
    "\n",
    "combined_list = holidays + weekends + non_work_hours\n",
    "\n",
    "df.query('transaction_id.isin(@combined_list)')['transaction_id']"
   ],
   "id": "487ccbda0d621216"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2144\n",
    "\n",
    "```A major airline has enlisted Tata Consultancy's help to improve customer satisfaction on its flights. Their goal is to increase customer satisfaction among people between the ages of 30 and 40. You've been tasked with calculating the customer satisfaction average for this age group across all three flight classes for 2022. Return the class with the average of satisfaction rounded to the nearest whole number. Note: Only survey results from flights in 2022 are included in the dataset.```"
   ],
   "id": "236a9e64fef731b1"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql8"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT class, ROUND(AVG(satisfaction)) AS pc_score\n",
    "FROM survey_results AS sr\n",
    "         JOIN loyalty_customers AS lc ON sr.cust_id = lc.cust_id\n",
    "WHERE age BETWEEN 30 AND 39\n",
    "GROUP BY class"
   ],
   "id": "ab8312a1ae2b234e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(survey_results, loyalty_customers, how='inner', on='cust_id')\n",
    "\n",
    "df.query('age.between(30, 39)').groupby('class', as_index=False).agg(avg_score=('satisfaction', 'mean')).round()"
   ],
   "id": "eed181d7a21a92c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2145\n",
    "\n",
    "```Tiktok want to find out what were the top two most active user days during an advertising campaign they ran in the first week of August 2022 (between the 1st to the 7th). Identify the two days with the highest user activity during the advertising campaign. They've also specified that user activity must be measured in terms of unique users. Output the day, date, and number of users. Be careful that some function can add a padding (whitespaces) around the string, for a solution to be correct you should trim the extra padding.```"
   ],
   "id": "9cfa42e7ff98bd5c"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql10"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT TO_CHAR(date_visited, 'Day')                          AS day_of_week,\n",
    "                    DATE_TRUNC('day', date_visited)::DATE                 AS date_visited,\n",
    "                    COUNT(DISTINCT user_id)                               AS n_users,\n",
    "                    DENSE_RANK() OVER (ORDER BY COUNT\n",
    "                                                (DISTINCT user_id) DESC ) AS rnk\n",
    "             FROM user_streaks\n",
    "             WHERE DATE_TRUNC('day', date_visited) BETWEEN '2022-08-01' AND '2022-08-07'\n",
    "             GROUP BY day_of_week, date_visited)\n",
    "SELECT day_of_week, date_visited, n_users\n",
    "FROM cte\n",
    "WHERE rnk <= 2"
   ],
   "id": "2ddab0885c6d24d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = user_streaks.query('date_visited >= \"2022-08-01\" and date_visited <= \"2022-08-07\"')\n",
    "\n",
    "df['date'] = df['date_visited'].dt.date\n",
    "df['day_of_week'] = df['date_visited'].dt.strftime('%A')\n",
    "\n",
    "df.groupby(['day_of_week', 'date'], as_index=False).agg(n_users=('user_id', 'nunique')).nlargest(2, 'n_users',\n",
    "                                                                                                 keep='all')"
   ],
   "id": "51d98f5271a4abd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2148\n",
    "\n",
    "```You have been asked to calculate the rolling average for book sales in 2022. A rolling average continuously updates a data set's average to include all data in the set up to that point. For example, the rolling average for February would be calculated by adding the book sales from January and February and dividing by two; the rolling average for March would be calculated by adding the book sales from January, February, and March and dividing by three; and so on. Output the month, the sales for that month, and an extra column containing the rolling average rounded to the nearest whole number.```"
   ],
   "id": "54127dd69097c5d0"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql9"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT EXTRACT(MONTH FROM order_date)                                                                         AS order_month,\n",
    "       SUM(quantity * unit_price)                                                                             AS sales,\n",
    "       ROUND(AVG(SUM(quantity * unit_price))\n",
    "             OVER (ORDER BY EXTRACT(MONTH FROM order_date) ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)) AS rolling_average\n",
    "FROM book_orders AS bo\n",
    "         JOIN amazon_books AS ab ON bo.book_id = ab.book_id\n",
    "WHERE DATE_TRUNC('year', order_date) = '2022-01-01'\n",
    "GROUP BY order_month"
   ],
   "id": "1fa62e7c7c8761a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(book_orders, amazon_books, how='inner', on='book_id')\n",
    "\n",
    "df['order_month'] = df['order_date'].dt.month\n",
    "\n",
    "df['sales'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "result_df = df.query('order_date.dt.year == 2022').groupby('order_month', as_index=False).agg(\n",
    "    monthly_sales=('sales', 'sum'))\n",
    "\n",
    "result_df['rolling_average'] = result_df['monthly_sales'].expanding().mean().round()\n",
    "\n",
    "result_df"
   ],
   "id": "7376d3810ebcbcd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2149\n",
    "\n",
    "```Following a recent advertising campaign, you have been asked to compare the sales of consumable products across all brands. Compare the brands by finding the percentage of unique customers (among all customers in the dataset) who purchased consumable products from each brand. Your output should contain the brand_name and percentage_of_customers rounded to the nearest whole number and ordered in descending order.```"
   ],
   "id": "9d78d6c1e5d20f78"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql11"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT brand_name,\n",
    "       ROUND(COUNT(DISTINCT customer_id) FILTER (WHERE product_family = 'CONSUMABLE') *\n",
    "             100.0 / (SELECT COUNT(DISTINCT customer_id) FROM online_orders)) AS pc_cust\n",
    "FROM online_orders oo\n",
    "         JOIN online_products op USING (product_id)\n",
    "GROUP BY brand_name\n",
    "HAVING COUNT(DISTINCT customer_id) FILTER (WHERE product_family = 'CONSUMABLE') > 0"
   ],
   "id": "22f4306c37c2dae7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_customers = online_orders['customer_id'].nunique()\n",
    "\n",
    "df = pd.merge(online_orders, online_products, how='inner', on='product_id')\n",
    "\n",
    "df.query('product_family == \"CONSUMABLE\"').groupby('brand_name', as_index=False).agg(\n",
    "    n_customers=('customer_id', lambda x: x.nunique() * 100 / n_customers))"
   ],
   "id": "f27977fcef7cc7ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2151\n",
    "\n",
    "```You have been asked to find the number of employees hired between the months of January and July in the year 2022 inclusive. Your output should contain the number of employees hired in this given time frame.```"
   ],
   "id": "e147377bc939c673"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql5"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT COUNT(id) AS hired_emp\n",
    "FROM employees\n",
    "WHERE DATE_TRUNC('month', joining_date) BETWEEN '2022-01-01' AND '2022-07-01'"
   ],
   "id": "fa7c053b45596950"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = employees\n",
    "\n",
    "df[df['joining_date'].dt.to_period('M').between('2022-01-01', '2022-07-01')]['id'].count()"
   ],
   "id": "dc09424f88bcfa14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2152\n",
    "\n",
    "```It's time to find out who is the top employee. You've been tasked with finding the employee (or employees, in the case of a tie) who have received the most votes. A vote is recorded when a customer leaves their 10-digit phone number in the free text customer_response column of their sign up response (occurrence of any number sequence with exactly 10 digits is considered as a phone number). Output the top employee and the number of customer responses that left a number.```"
   ],
   "id": "1a3ebe3b51662b7e"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql12"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT employee_id,\n",
    "                    COUNT(employee_id)                                   AS cust_numbers,\n",
    "                    DENSE_RANK() OVER (ORDER BY COUNT(employee_id) DESC) AS rnk\n",
    "             FROM customer_responses\n",
    "             WHERE customer_response ~ '\\d{10}'\n",
    "             GROUP BY employee_id)\n",
    "SELECT employee_id, cust_numbers\n",
    "FROM cte\n",
    "WHERE rnk = 1"
   ],
   "id": "24e330fdb127123c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = customer_responses\n",
    "\n",
    "df.query('customer_response.str.contains(\"\\d{10}\", regex=True)').groupby('employee_id', as_index=False).agg(\n",
    "    cust_numbers=('employee_id', 'count')).nlargest(1, 'cust_numbers', keep='all')"
   ],
   "id": "703a6479879a6d82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2154\n",
    "\n",
    "```The company you are working for wants to anticipate their staffing needs by identifying their top two busiest times of the week. To find this, each day should be segmented into differents parts using following criteria: Morning: Before 12 p.m. (not inclusive) Early afternoon: 12 -15 p.m. Late afternoon: after 15 p.m. (not inclusive) Your output should include the day and time of day combination for the two busiest times, i.e. the combinations with the most orders, along with the number of orders (e.g. top two results could be Friday Late afternoon with 12 orders and Sunday Morning with 10 orders). The company has also requested that the day be displayed in text format (i.e. Monday). Note: In the event of a tie in ranking, all results should be displayed.```"
   ],
   "id": "48e4fe0e4a62a94c"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql13"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT TO_CHAR(timestamp, 'Day')                         AS day_of_week\n",
    "                  , CASE\n",
    "                        WHEN EXTRACT(HOUR FROM timestamp) BETWEEN 0 AND 11 THEN 'Morning'\n",
    "                        WHEN EXTRACT(HOUR FROM timestamp) BETWEEN 12 AND 15\n",
    "                            THEN 'Early afternoon'\n",
    "                        ELSE 'Late afternoon' END                     AS time_of_day\n",
    "                  , COUNT(order_id)                                   AS total_orders\n",
    "                  , DENSE_RANK() OVER (ORDER BY COUNT(order_id) DESC) AS rnk\n",
    "             FROM sales_log\n",
    "             GROUP BY day_of_week, time_of_day)\n",
    "SELECT day_of_week\n",
    "     , time_of_day\n",
    "     , total_orders\n",
    "FROM cte\n",
    "WHERE rnk <= 2"
   ],
   "id": "693dba981aab096c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = sales_log\n",
    "\n",
    "df['date'] = df['timestamp'].dt.strftime('%A')\n",
    "\n",
    "df['time_of_day'] = np.select([df['timestamp'].dt.hour.between(0, 11), df['timestamp'].dt.hour.between(12, 15)],\n",
    "                              ['Morning', 'Early afternoon'], 'Late afternoon')\n",
    "\n",
    "df.groupby(['date', 'time_of_day'], as_index=False).agg(total_orders=('order_id', 'count')).nlargest(2, 'total_orders',\n",
    "                                                                                                     keep='all')"
   ],
   "id": "e5aa432df0e276c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2156\n",
    "\n",
    "```You have been tasked with finding the worker IDs of individuals who logged in between the 13th to the 19th inclusive of December 2021. In your output, provide the unique worker IDs for the dates requested.'```"
   ],
   "id": "ae5b0f8efb62a0c9"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql4"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT DISTINCT worker_id\n",
    "FROM worker_logins\n",
    "WHERE login_timestamp BETWEEN '2021-12-13' AND '2021-12-20'"
   ],
   "id": "2380c2c3d1067fd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = worker_logins\n",
    "\n",
    "df.query('login_timestamp.between(\"2021-12-13\", \"2021-12-19\")')['worker_id'].drop_duplicates()"
   ],
   "id": "a3e18311e87ad080"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2157\n",
    "\n",
    "```You have been asked to compare sales of the current month, May, to those of the previous month, April. The company requested that you only display products whose sales (UNITS SOLD * PRICE) have increased by more than 10% from the previous month to the current month. Your output should include the product id and the percentage growth in sales.```"
   ],
   "id": "991e455995458433"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql14"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "WITH cte AS (SELECT product_id,\n",
    "                    DATE_TRUNC('month', date)                                         AS period,\n",
    "                    SUM(units_sold * cost_in_dollars)                                 AS sales,\n",
    "                    LAG(SUM(units_sold * cost_in_dollars))\n",
    "                    OVER (PARTITION BY product_id ORDER BY DATE_TRUNC('month', date)) AS prev_sales\n",
    "             FROM online_orders\n",
    "             WHERE DATE_TRUNC('month', date) IN ('2022-04-01', '2022-05-01')\n",
    "             GROUP BY product_id, period)\n",
    "SELECT product_id, (sales - prev_sales) * 100.0 / prev_sales AS pc_growth\n",
    "FROM cte\n",
    "WHERE prev_sales IS NOT NULL\n",
    "  AND (sales - prev_sales) * 100.0 / prev_sales >= 10"
   ],
   "id": "da729c5c258d57ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = online_orders\n",
    "\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "\n",
    "df['sales'] = df['units_sold'] * df['cost_in_dollars']\n",
    "\n",
    "groped_df = df[(df['date'].dt.to_period('M') == '2022-04') | (df['date'].dt.to_period('M') == '2022-05')].groupby(\n",
    "    ['product_id', 'month'], as_index=False).agg(total_sales=('sales', 'sum'))\n",
    "\n",
    "groped_df['prev_sales'] = groped_df.groupby('product_id')['total_sales'].shift(1)\n",
    "\n",
    "groped_df['pc_growth'] = (groped_df['total_sales'] - groped_df['prev_sales']) * 100 / groped_df['prev_sales']\n",
    "\n",
    "groped_df[(~groped_df['prev_sales'].isnull()) & (groped_df['pc_growth'] > 10)][['product_id', 'pc_growth']]"
   ],
   "id": "784866eaf703ccbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2159\n",
    "\n",
    "```You have been asked to get a list of all the sign up IDs with transaction start dates in either April or May. Since a sign up ID can be used for multiple transactions only output the unique ID. Your output should contain a list of non duplicated sign-up IDs.```"
   ],
   "id": "9a4bcd0d2759dbb8"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT DISTINCT signup_id\n",
    "FROM transactions\n",
    "WHERE DATE_TRUNC('month', transaction_start_date)::DATE IN ('2020-04-01', '2020-05-01')"
   ],
   "id": "87a6b9a77f8998e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = transactions\n",
    "\n",
    "df.query('transaction_start_date >= \"2020-04-01\" & transaction_start_date < \"2020-06-01\"')['signup_id'].unique()"
   ],
   "id": "86ff2770bb7defb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ID 2160\n",
    "\n",
    "```The sales division is investigating their sales for the past month in Oregon. Calculate the total revenue generated from Oregon-based customers for April.```"
   ],
   "id": "b0d924580a3c409c"
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%sql\n",
    "SELECT SUM(cost_in_dollars * units_sold) AS total_sales\n",
    "FROM online_orders AS oo\n",
    "         JOIN online_customers AS oc ON oo.customer_id = oc.id\n",
    "WHERE state ILIKE 'oregon'\n",
    "  AND DATE_TRUNC('month', date) = '2022-04-01'"
   ],
   "id": "7fde100d304b2da2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(online_orders, online_customers, how='inner', left_on='customer_id', right_on='id')\n",
    "\n",
    "df['sales'] = df['cost_in_dollars'] * df['units_sold']\n",
    "\n",
    "df.query('state == \"Oregon\" & date.between(\"2022-04-01\", \"2022-04-30\")')['sales'].sum()"
   ],
   "id": "bf2e2f575dc5e9e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
